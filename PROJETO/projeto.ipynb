{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def parseRDD(point):\n",
    "    \"\"\" Converte um ponto de metricas da base de dados para uma tupla (id, vetor de floats).\n",
    "        Recebe um ponto onde o primeiro campo eh o id do vertice os 13 seguintes sao os valores para cada metrica\n",
    "        e retorna uma tupla composta pelo id e pelas 13 metricas (vetor de floats).\n",
    "    Args:\n",
    "        point (str): uma string onde os termos estao separados por ',', sendo o primeiro campo o id do vertice e \n",
    "        os 13 seguintes os valores para cada metrica\n",
    "    Returns:\n",
    "        (id, []): uma tupla composta pelo id do vertice e uma lista dos valores de 13 metricas\n",
    "    \"\"\"\n",
    "    data = point.split(';')\n",
    "    floatMetrics = [float(i) for i in data[1:]]\n",
    "    return (data[0], floatMetrics)\n",
    "\n",
    "def isNotZero(parsedPoint):\n",
    "    \"\"\" Retorna true se o ponto contem alguma metrica diferente de 0.\n",
    "    Args:\n",
    "        parsedPoint (str, []): uma tupla composta pelo id do vertice e lista de metricas\n",
    "    Returns:\n",
    "        bool: True se a lista contém pelo menos um valor nao nulo ou False se a somatoria da lista eh nula\n",
    "    \"\"\"\n",
    "    return sum(parsedPoint[1]) > 0\n",
    "\n",
    "def normalize(parsedPoint, means, standardDeviations, maxs, mins, normalizationType):\n",
    "    \"\"\" Normaliza um ponto. Recebe um ponto cujas valores maximo e minimo para as metricas \n",
    "        podem ser muito amplos e retorna um ponto cujas metricas estao entre 0 e 1.0.\n",
    "    Args:\n",
    "        parsedPoint (str, []): uma tupla composta pelo id do vertice e lista de metricas\n",
    "        means ([]): lista de medias das metricas\n",
    "        standardDeviations (list): lista de desvios-padrao das metricas\n",
    "        maxs ([]): lista de maximos das metricas\n",
    "        mins ([]): lista de minimos das metricas\n",
    "        normalizationType (str): tipo de normalizacao ('reescaling' | 'standard_score')\n",
    "    Returns:\n",
    "        (str, []): uma tupla de id (str) e metricas normalizadas ([])\n",
    "    \"\"\"\n",
    "    nodeId = parsedPoint[0]\n",
    "    metrics = parsedPoint[1]\n",
    "    numberOfMetrics = len(means) # numero de metricas == numero de medias == numero de desvios-padrao\n",
    "    if normalizationType == 'standard_score':\n",
    "        normalizedMetrics = [(metrics[i] - means[i])/standardDeviations[i] for i in range(numberOfMetrics)]\n",
    "    elif normalizationType == 'reescaling':\n",
    "         normalizedMetrics = [(metrics[i] - mins[i])/(maxs[i]-mins[i]) for i in range(numberOfMetrics)]\n",
    "    return (nodeId, normalizedMetrics)\n",
    "\n",
    "def euclidianDistance(pointA, pointB):\n",
    "    \"\"\" Calcula a distancia euclidiana entre dois pontos. Recebe dois pontos e retorna a distancia\n",
    "        euclidiana entre eles.\n",
    "    Args:\n",
    "        pointA ([]): lista de floats\n",
    "        pointB ([]): lista de floats\n",
    "    Returns:\n",
    "        float: a distancia entre dois pontos\n",
    "    \"\"\"\n",
    "    numberOfMetrics = len(pointA) # numero de metricas de A e B eh igual a 13\n",
    "    squaredDifferenceBetweenMetrics = [math.pow(pointA[i] - pointB[i], 2) for i in range(numberOfMetrics)]\n",
    "    return math.sqrt(sum(squaredDifferenceBetweenMetrics))\n",
    "\n",
    "def chooseRandomPoints(points, numberOfPoints):\n",
    "    \"\"\" Escolhe um ponto aleatorio dentre uma lista de pontos. \n",
    "        Recebe uma lista de pontos e retorna um ponto dessa lista.\n",
    "    Args:\n",
    "        points (RDD): RDD de pontos\n",
    "        numberOfPoints (int): numero de pontos a serem escolhidos\n",
    "    Returns:\n",
    "        points ([[]]): uma lista de lista de metricas representando n pontos\n",
    "    \"\"\"\n",
    "    return points.takeSample(False, numberOfPoints)\n",
    "    \n",
    "def areCentroidsDifferent(pointA, pointB):\n",
    "    \"\"\" Verifica se dois pontos sao diferentes, com base nas listas de metricas.\n",
    "        Recebe dois pontos e returna True ou False.\n",
    "    Args:\n",
    "        pointA: um ponto do tipo [], em que contem metricas do tipo float\n",
    "        ponttB: um ponto do tipo [], em que contem metricas do tipo float\n",
    "    Returns:\n",
    "        bool: True se pointA[i] != pointB[i] para todo i ou False caso contrario\n",
    "    \"\"\"\n",
    "    for i in range(len(pointA)):\n",
    "        if pointA[i] != pointB[i]:\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "def kmeans(data, k, iteractions):\n",
    "    \"\"\" Base do bisect-kmeans. Recebe uma RDD de dados, um k=2 e o numero de iteracoes maximo e retorna dois clusters.\n",
    "    Args:\n",
    "        data (RDD): RDD de pontos do tipo (str, [])\n",
    "        k (int): numero de clusters a serem gerados. Padrao para bisect é 2 por vez\n",
    "        iteractions (int): numero de interacoes maximo\n",
    "    Returns:\n",
    "        clusters (RDD): um RDD contendo dois clusters. \n",
    "                        Cada ponto eh mapeado para (idClusters, idPonto, metricas)\n",
    "                        idClusters eh ou 0 ou 1\n",
    "                        metricas eh uma lista de floats\n",
    "        centroids ([[]]): lista de listas de metricas representando os centroides\n",
    "    \"\"\"\n",
    "    # seleciona k pontos aleatorios e atribui a lista inicial de centroides\n",
    "    centroids = [p[1] for p in chooseRandomPoints(data, k)] \n",
    "    \n",
    "    # roda kmeans ateh o limite de iteractions\n",
    "    for i in range(iteractions):\n",
    "        print('\\tK-MEANS %s de %s' %(i+1, iteractions))\n",
    "        # calcula distancia entre cada ponto (segundo elemento da tupla) e os centroides, e atribui a cada ponto o id do centroide cuja distanca eh menor\n",
    "        clustersRDD = data.map(lambda x:(np.argmin([euclidianDistance(x[1], c) for c in centroids]), x[0], x[1]))\n",
    "        \n",
    "        # refaz lista de centroides, calculando o ponto medio dos pontos de cada cluster\n",
    "        newCentroids = (clustersRDD\n",
    "                        .map(lambda x:(x[0], [x[2],1])) # mapeia cada ponto para (indice do centroide, [vetor de metricas, 1])\n",
    "                        .reduceByKey(lambda x,y:([(np.array(x[0]) + np.array(y[0])),(x[1] + y[1])])) # reduz conjunto de pontos com mesmo indice do centroide para a somatoria dos vetores de metricas\n",
    "                        .map(lambda x:list(np.array(x[1][0])/(x[1][1]))) # divide a somatoria dos vetores pelo numero de pontos\n",
    "                       ).collect()\n",
    "\n",
    "        # caso numero de centroides mude, seleciona centroides faltantes de forma aleatoria\n",
    "        if len(newCentroids) != len(centroids):\n",
    "            diff = len(centroids) - len(newCentroids)\n",
    "            newCentroids.extend([p[1] for p in chooseRandomPoints(data, diff)])\n",
    "        \n",
    "        # verifica se centroides mudaram\n",
    "        centroidsHaveChanged = [areCentroidsDifferent(centroids[i], newCentroids[i]) for i in range(len(centroids))]\n",
    "        \n",
    "        if True not in centroidsHaveChanged:\n",
    "            return clustersRDD, centroids\n",
    "        else:\n",
    "            centroids = newCentroids\n",
    "    return clustersRDD, centroids\n",
    "\n",
    "def getClustersByCount(cluster1, cluster2):\n",
    "    \"\"\" Verifica qual dos clusters possui mais elementos e os retorna ordenado pela quantidade crescente de elementos.\n",
    "    Args:\n",
    "        cluster1 (RDD): RDD contendo pontos cujas chaves sao 0\n",
    "        cluster2 (RDD): RDD contendo pontos cujas chaves sao 1\n",
    "    Returns:\n",
    "        clusterMaior (RDD), clusterMenor (RDD): retorna o maior e o menor dos clusters, nesta ordem\n",
    "    \"\"\"\n",
    "    if cluster1.count() > cluster2.count():\n",
    "        return cluster1, cluster2\n",
    "    else:\n",
    "        return cluster2, cluster1\n",
    "    \n",
    "def getSSE(cluster, centroid):\n",
    "    \"\"\" Calcula a soma das distancias entre cada ponto e o centroide do cluster.\n",
    "        Recebe um cluster e retorna a somatoria das distancias euclidianas de cada ponto ao centroide do cluster.\n",
    "    Args:\n",
    "        cluster (RDD): RDD contendo pontos\n",
    "        centroid ([]): centroide do cluster\n",
    "    Returns:\n",
    "        sse (float): a somatoria das distancias euclidianas entre cada ponto e o centroide\n",
    "    \"\"\"\n",
    "    return cluster.map(lambda x:euclidianDistance(x[2], centroid)).reduce(lambda x,y:x+y)\n",
    "    \n",
    "def bisectKmeans(data, k, bisects, iteractions):\n",
    "    \"\"\" Algoritmo principal do bisect-kmeans. Recebe uma RDD de dados, o numero de clusters a serem gerados,\n",
    "        o numero de iteracoes maximo do subalgoritmo kmeans e um boleano indicando se pode haver clusters vazios\n",
    "    Args:\n",
    "        data (RDD): RDD de pontos do tipo (idPonto, metricas), onde idPonto eh um str e metricas eh uma lista de floats\n",
    "        k (int): numero de clusters\n",
    "        bisects (int): numero de bifurcacoes\n",
    "        iteractions (int): numero de iteracoes do k-means\n",
    "    Returns:\n",
    "        finalClusters ([]): lista de pontos do tipo (idPonto, metricas), \n",
    "                            len(finalClusters) eh garantido ser k, se forceAllClusterWithPoints for True\n",
    "                            cada cluster contem x pontos\n",
    "    \"\"\"\n",
    "    finalClusters = [data]\n",
    "    while(len(finalClusters) != k):\n",
    "        # coleta ultimo cluster para usar no k-means\n",
    "        clusterToSplit = finalClusters.pop()   \n",
    "        \n",
    "        # lista de somatorios de erros quadraticos\n",
    "        sse = []\n",
    "        \n",
    "        # lista temporaria de clusters\n",
    "        tmpClusters = []\n",
    "        \n",
    "        # gera dois clusters bisect vezes e calcula os sseTotal para cada par de clusters\n",
    "        for i in range(bisects):\n",
    "            print('BISECT %s de %s' %(i+1, bisects))\n",
    "            clustersRDD, centroids = kmeans(data=clusterToSplit, k=2, iteractions=iteractions)\n",
    "            tmpClusters.append(clustersRDD.filter(lambda x:x[0] == 0))\n",
    "            tmpClusters.append(clustersRDD.filter(lambda x:x[0] == 1))\n",
    "            sse1 = getSSE(tmpClusters[-2], centroids[0])\n",
    "            sse2 = getSSE(tmpClusters[-1], centroids[1])\n",
    "            sse.append(sse1 + sse2)\n",
    "        \n",
    "        # coleta indice do menor sseTotal\n",
    "        minSseIndex = np.argmin(sse)\n",
    "        \n",
    "        # ordena do maior para o menor os dois clusters cuja sseTotal eh menor\n",
    "        largerCluster, minorCluster = getClustersByCount(tmpClusters[minSseIndex*2], tmpClusters[minSseIndex*2 + 1])\n",
    "\n",
    "        # adiciona a lista de clusters o menor, depois o maior\n",
    "        finalClusters.append(minorCluster.map(lambda x:(x[1], x[2])))\n",
    "        finalClusters.append(largerCluster.map(lambda x:(x[1], x[2]))) \n",
    "        print('--------\\nK %s de %s\\n--------' %(len(finalClusters), k))\n",
    "    return finalClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 76.8 ms\n"
     ]
    }
   ],
   "source": [
    "fileName = ('metricas_t.csv')\n",
    "rawRDD = sc.textFile(fileName)\n",
    "metricsHeader = rawRDD.take(1)[0]\n",
    "metricsRDD = (rawRDD\n",
    "              .filter(lambda x: x != metricsHeader)\n",
    "              .map(lambda x:parseRDD(x))\n",
    "              .filter(lambda x: isNotZero(x))\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "maxs = []\n",
    "mins = []\n",
    "stdevs = []\n",
    "for i in range(13):\n",
    "    metricI = metricsRDD.map(lambda x: x[1][i])\n",
    "    maxs.append(metricI.max())\n",
    "    mins.append(metricI.min())\n",
    "    means.append(metricI.mean())\n",
    "    stdevs.append(metricI.stdev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.92 ms\n"
     ]
    }
   ],
   "source": [
    "normalizedMetricsRDD = metricsRDD.map(lambda x:normalize(x, means, stdevs, maxs, mins, 'standard_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BISECT 1 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 2 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 3 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 4 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 5 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 6 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "--------\n",
      "K 2 de 4\n",
      "--------\n",
      "BISECT 1 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "BISECT 2 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 3 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 4 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 5 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 6 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "--------\n",
      "K 3 de 4\n",
      "--------\n",
      "BISECT 1 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 2 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 3 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 4 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 5 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "\tK-MEANS 3 de 5\n",
      "\tK-MEANS 4 de 5\n",
      "\tK-MEANS 5 de 5\n",
      "BISECT 6 de 6\n",
      "\tK-MEANS 1 de 5\n",
      "\tK-MEANS 2 de 5\n",
      "--------\n",
      "K 4 de 4\n",
      "--------\n",
      "time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "clusters = bisectKmeans(data=normalizedMetricsRDD, iteractions=5, k=4, bisects=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 possui 429 pontos\n",
      "cluster 2 possui 655 pontos\n",
      "cluster 3 possui 177 pontos\n",
      "cluster 4 possui 723 pontos\n",
      "------------------------\n",
      "total possui 1984 pontos\n",
      "time: 383 ms\n"
     ]
    }
   ],
   "source": [
    "tamanhos = []\n",
    "for index, c in enumerate(clusters):\n",
    "    tamanhos.append(c.count())\n",
    "    print('cluster %s possui %s pontos' %(index + 1, tamanhos[index]))\n",
    "#     c.saveAsTextFile('12threads_i5k10b3/%s' %index)\n",
    "    \n",
    "print('------------------------\\ntotal possui %s pontos' %sum(tamanhos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
